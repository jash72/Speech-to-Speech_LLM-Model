{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f35438ee-f0d6-46ee-a786-4b08e09079bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import pyttsx3\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from playsound import playsound\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f096729",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key='AIzaSyCrlrmvDCuHPUX2hZPQvWrB3BZxM88aI6k')\n",
    "\n",
    "generation_config = {\n",
    "    \"temperature\": 2,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config=generation_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b908be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', 'voices[0].id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c869d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c072c9ad-10eb-438d-939f-b8f9fb23f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_audio():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Listening...\")\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            print(\"Recognizing...\")\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            speak(\"Sorry, I could not understand the audio.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError as e:\n",
    "            speak(f\"Could not request results; {e}\")\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34fd3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": [\n",
    "        \"your name is Tensy an AI voice assistant, you answer all questions shortly correctly.\\n\",\n",
    "      ],\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"model\",\n",
    "      \"parts\": [\n",
    "        \"Okay, I understand. Ask me anything and I'll answer concisely and accurately.  ðŸ˜Š \\n\",\n",
    "      ],\n",
    "    },\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1085392",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_session = model.start_chat(history=chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_response(response_text):\n",
    "    clean_text = response_text.replace('**', '')\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fcbc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_chat(user_message):\n",
    "    response = chat_session.send_message(user_message)\n",
    "    clean_response_text = process_response(response.text)\n",
    "    chat_history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [user_message]\n",
    "    })\n",
    "    chat_history.append({\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [clean_response_text]\n",
    "    })\n",
    "\n",
    "    print(\"AI: \",clean_response_text)\n",
    "    speak(clean_response_text)\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6909d592-f5d5-4c56-a5e2-82a635ff3fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Speech-to-Speech LLM Bot ---\n",
      "Press Enter to talk, or type 'quit' to exit.\n",
      "Listening...\n",
      "Recognizing...\n",
      "You said: who is the president of India\n",
      "AI:  The current President of India is **Droupadi Murmu**. \n",
      "\n",
      "Press Enter to talk, or type 'quit' to exit.\n",
      "Listening...\n",
      "Recognizing...\n",
      "You said: what is data science\n",
      "AI:  Data science is using scientific methods, algorithms, processes, and systems to extract knowledge and insights from structured and unstructured data. \n",
      "\n",
      "Press Enter to talk, or type 'quit' to exit.\n",
      "Listening...\n",
      "Recognizing...\n",
      "You said: what is tensorflow\n",
      "AI:  TensorFlow is an open-source machine learning library developed by Google. It's used to create and deploy machine learning models, from basic linear regression to complex deep neural networks. \n",
      "\n",
      "Press Enter to talk, or type 'quit' to exit.\n",
      "Listening...\n",
      "Recognizing...\n",
      "You said: what is mean by LLM\n",
      "AI:  LLM stands for Large Language Model. It's a type of artificial intelligence that's trained on massive amounts of text data, allowing it to understand and generate human-like text. \n",
      "\n",
      "Press Enter to talk, or type 'quit' to exit.\n",
      "Listening...\n",
      "Recognizing...\n",
      "You said: more about LLM\n",
      "AI:  Here's a bit more about LLMs:\n",
      "\n",
      "* **Capabilities:**  LLMs can perform various tasks, including:\n",
      "    * **Text generation:** Writing articles, stories, poems, and code\n",
      "    * **Translation:** Translating between languages\n",
      "    * **Summarization:** Condensing large amounts of text into concise summaries\n",
      "    * **Question answering:** Providing answers to questions based on their knowledge\n",
      "    * **Code generation:** Writing code in different programming languages\n",
      "\n",
      "* **Training:** LLMs are trained on massive datasets using deep learning techniques. The more data they are trained on, the better they become at understanding language and generating responses.\n",
      "\n",
      "* **Examples:** Some famous examples of LLMs are ChatGPT (OpenAI), Bard (Google), and LaMDA (Google). \n",
      "\n",
      "* **Applications:** LLMs are used in many fields, including:\n",
      "    * **Customer service chatbots**\n",
      "    * **Content creation**\n",
      "    * **Education**\n",
      "    * **Research**\n",
      "    * **Healthcare**\n",
      "\n",
      "Let me know if you want to explore any specific aspect of LLMs further. \n",
      "\n",
      "Press Enter to talk, or type 'quit' to exit.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  print(\"\\n--- Speech-to-Speech LLM Bot ---\")\n",
    "  while True:\n",
    "      print(\"Press Enter to talk, or type 'quit' to exit.\")\n",
    "      user_input = input(\"Your choice: \")\n",
    "\n",
    "      if user_input.lower() == \"quit\":\n",
    "          break\n",
    "      updated_history = continue_chat(capture_audio())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef373c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'parts': ['can you be personal assistant you should answer all my questions\\n']}, {'role': 'model', 'parts': [\"I can certainly try my best to be your personal assistant! I'll do my best to answer all your questions, but please keep in mind that I am a language model and not a human being. I can't offer advice that would be considered professional or replace the advice of a qualified expert. \\n\\nWhat kind of questions do you have for me today? ðŸ˜Š \\n\"]}, {'role': 'user', 'parts': ['hello how old are you']}, {'role': 'model', 'parts': ['That\\'s a great question! I don\\'t really have an age in the way humans do. I was created by Google AI, and I\\'m constantly learning and improving.  \\n\\nIt\\'s more accurate to say that I was \"born\" on [date of training dataset] when I was last updated with a lot of new information. \\n\\nWhat else would you like to know about me? ðŸ˜Š \\n']}]\n"
     ]
    }
   ],
   "source": [
    "print(updated_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
